train:
  epochs: 1000
  batch_size: 16
  learning_rate: 1e-3
  num_workers: 0
  resume: False
  checkpoint_path: checkpoints/SSR_epoch_x_acc_x.pth
  lr: 1e-3
  patience: 3
  factor: 0.95

# -----------------------------------------------------------------------------------------------------
# BatchNorm1d(39, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) torch.Size([16, 39, 300])
# -----------------------------------------------------------------------------------------------------
# Conv1d(39, 26, kernel_size=(5,), stride=(1,), padding=same) torch.Size([16, 26, 300])
# -----------------------------------------------------------------------------------------------------
# ReLU() torch.Size([16, 26, 300])
# -----------------------------------------------------------------------------------------------------
# Conv1d(26, 13, kernel_size=(5,), stride=(1,), padding=same) torch.Size([16, 13, 300])
# -----------------------------------------------------------------------------------------------------
# ReLU() torch.Size([16, 13, 300])
# -----------------------------------------------------------------------------------------------------
# MaxPool1d(kernel_size=6, stride=2, padding=0, dilation=1, ceil_mode=False) torch.Size([16, 13, 148])
# -----------------------------------------------------------------------------------------------------
# Dropout(p=0.1, inplace=False) torch.Size([16, 13, 148])
# -----------------------------------------------------------------------------------------------------
# Conv1d(13, 5, kernel_size=(5,), stride=(1,), padding=same) torch.Size([16, 5, 148])
# -----------------------------------------------------------------------------------------------------
# ReLU() torch.Size([16, 5, 148])
# -----------------------------------------------------------------------------------------------------
# Conv1d(5, 1, kernel_size=(5,), stride=(1,), padding=same) torch.Size([16, 1, 148])
# -----------------------------------------------------------------------------------------------------
# ReLU() torch.Size([16, 1, 148])
# -----------------------------------------------------------------------------------------------------
# MaxPool1d(kernel_size=6, stride=2, padding=0, dilation=1, ceil_mode=False) torch.Size([16, 1, 72])
# -----------------------------------------------------------------------------------------------------
# Flatten(start_dim=1, end_dim=-1) torch.Size([16, 72])
# -----------------------------------------------------------------------------------------------------
# Linear(in_features=72, out_features=8, bias=True) torch.Size([16, 8])
# -----------------------------------------------------------------------------------------------------
# Softmax(dim=1) torch.Size([16, 8])
# -----------------------------------------------------------------------------------------------------
single_speech_recog_net:
  in_channels: 39
  in_length: 300
  classes: 8
  padding: same
  hidden_layer: 
    - 26
    - 13
    - 5
    - 1
  maxpool:
    layers: 2 
    # the 2nd in_len is invalid, just as a reference.
    in_len:
      - 300
      - 150
    pool_padding_size:
      - 0
      - 0
    dilation:
      - 1
      - 1
    kernal_size:
      - 6
      - 6
    stride:
      - 2
      - 2
    